{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307bed2117cb797",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "import gc\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In questa cella ci andiamo a dichiarare il dataset di input, e i vari dataset di appoggio che servono per eseguire i vari step di preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51fee0d9f4688600"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Definizione delle directory di input e output\n",
    "input_dir = 'Dataset1'\n",
    "normalized_output_dir = 'NuovoDataset/Normalized'\n",
    "segmented_output_dir = 'NuovoDataset/Segmented'\n",
    "spectrogram_output_dir = 'NuovoDataset/Spectrograms'\n",
    "\n",
    "# Creare le directory di output se non esistono\n",
    "os.makedirs(normalized_output_dir, exist_ok=True)\n",
    "os.makedirs(segmented_output_dir, exist_ok=True)\n",
    "os.makedirs(spectrogram_output_dir, exist_ok=True)\n",
    "\n",
    "# Definizione della lunghezza desiderata in secondi e in campioni\n",
    "desired_length_sec = 4  # Durata desiderata in secondi\n",
    "sampling_rate = 192000  # Frequenza di campionamento (modifica se necessario)\n",
    "desired_length_samples = int(desired_length_sec * sampling_rate)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d96bf9e9c5472bae",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il seguente codice non è utile ai fini del preprocessing, ma vista la grande quantità di dati da processare, implementare dei checkpoint è una ottima risorsa per non rischiare di dover riiniziare il lavoro da capo "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58c516e94455df2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# File di checkpoint\n",
    "normalized_checkpoint_file = 'normalized_files.json'\n",
    "segmented_checkpoint_file = 'segmented_files.json'\n",
    "spectrogram_checkpoint_file = 'spectrogram_files.json'\n",
    "\n",
    "# Funzioni per caricare e salvare le liste di checkpoint\n",
    "def load_checkpoint(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            return set(json.load(f))\n",
    "    return set()\n",
    "\n",
    "def save_checkpoint(processed_files, filepath):\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(list(processed_files), f)\n",
    "\n",
    "# Carica i checkpoint\n",
    "normalized_files = load_checkpoint(normalized_checkpoint_file)\n",
    "segmented_files = load_checkpoint(segmented_checkpoint_file)\n",
    "spectrogram_files = load_checkpoint(spectrogram_checkpoint_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3186cf6621329c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "La prossima fase serve a normalizzare gli audio, in maniera tale da avere valori compresi tra 0 e 1 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b202fb42c3179b80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Lista per memorizzare i percorsi dei file audio\n",
    "audio_files = []\n",
    "# Scorrere ricorsivamente le cartelle nel dataset\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_files.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio trovati: {len(audio_files)}\")\n",
    "\n",
    "def normalize_audio(input_file, output_file):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Trova il valore massimo assoluto nel segnale audio\n",
    "    max_val = np.max(np.abs(audio_data))\n",
    "    \n",
    "    # Normalizza il segnale tra 0 e 1\n",
    "    normalized_audio = (audio_data / max_val + 1) / 2\n",
    "    \n",
    "    # Scrivi il file audio normalizzato\n",
    "    sf.write(output_file, normalized_audio, sample_rate)\n",
    "\n",
    "# Normalizzare tutti i file audio e salvarli nella directory di output corrispondente\n",
    "for file in tqdm(audio_files, desc='Normalizzazione degli audio'):\n",
    "    relative_path = os.path.relpath(file, input_dir)\n",
    "    output_file = os.path.join(normalized_output_dir, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    if file not in normalized_files:\n",
    "        normalize_audio(file, output_file)\n",
    "        normalized_files.add(file)\n",
    "        save_checkpoint(normalized_files, normalized_checkpoint_file)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1038a4679379b3b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adesso si passa alla divisione degli audio, per nostra convenzione dividiamo gli audio in 4 secondi"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b36079a16e84195"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "audio_norm = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset normalizzato\n",
    "for root, dirs, files in os.walk(normalized_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_norm.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio normalizzati: {len(audio_norm)}\")\n",
    "\n",
    "def split_audio(input_file, output_directory, segment_duration=4):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Calcola il numero di campioni per ogni segmento\n",
    "    segment_samples = int(segment_duration * sample_rate)\n",
    "    \n",
    "    # Ottieni il nome del file originale senza estensione\n",
    "    original_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    \n",
    "    # Inizializza il contatore per i segmenti\n",
    "    segment_counter = 0\n",
    "    \n",
    "    # Itera attraverso l'audio e salva i segmenti\n",
    "    for start in range(0, len(audio_data), segment_samples):\n",
    "        end = start + segment_samples\n",
    "        segment_data = audio_data[start:end]\n",
    "        \n",
    "        # Costruisci il nome del file per il segmento\n",
    "        segment_filename = f\"{original_filename}_segment_{segment_counter}.wav\"\n",
    "        output_file = os.path.join(output_directory, segment_filename)\n",
    "        \n",
    "        # Crea la directory di output se non esiste\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        \n",
    "        # Scrivi il file audio del segmento\n",
    "        sf.write(output_file, segment_data, sample_rate)\n",
    "        \n",
    "        # Incrementa il contatore dei segmenti\n",
    "        segment_counter += 1\n",
    "\n",
    "# Dividere tutti i file audio normalizzati in segmenti e salvarli nella directory di output corrispondente\n",
    "for file in tqdm(audio_norm, desc='Suddivisione degli audio'):\n",
    "    relative_path = os.path.relpath(file, normalized_output_dir)\n",
    "    output_directory = os.path.join(segmented_output_dir, os.path.dirname(relative_path))\n",
    "    \n",
    "    if file not in segmented_files:\n",
    "        split_audio(file, output_directory)\n",
    "        segmented_files.add(file)\n",
    "        save_checkpoint(segmented_files, segmented_checkpoint_file)\n",
    "\n",
    "audio_segmented = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset segmentato\n",
    "for root, dirs, files in os.walk(segmented_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_segmented.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio segmentati: {len(audio_segmented)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f88edf0072cd5d2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In quest ultimo blocco andiamo a generare effettivamente gli spettrogrammi prendendo in considerazione gli audio già splittati e normalizzati \n",
    "La soglia di memoria è solo un modo per liberare la RAM nel momento in cui si riempie troppo "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8675c68dadccb7eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "memory_threshold = 0.8  # Soglia di memoria (80%)\n",
    "\n",
    "def generate_spectrogram(file, output_folder):\n",
    "    # Controlla l'estensione del file\n",
    "    if file.endswith('.mp3'):\n",
    "        audio = AudioSegment.from_mp3(file).set_frame_rate(sampling_rate).set_channels(1)\n",
    "        y = np.array(audio.get_array_of_samples(), dtype=np.float32)\n",
    "        sr = audio.frame_rate\n",
    "    else:  # file.endswith('.wav')\n",
    "        y, sr = sf.read(file, always_2d=False)\n",
    "        if len(y.shape) > 1:  # Se stereo, converte in mono\n",
    "            y = librosa.to_mono(y.T)\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=sampling_rate)\n",
    "        sr = sampling_rate\n",
    "    \n",
    "    # Calcola lo spettrogramma STFT\n",
    "    D = np.abs(librosa.stft(y))  # Magnitude of the STFT\n",
    "    D_db = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    \n",
    "    # Creare la struttura delle directory di output mantenendo la stessa gerarchia\n",
    "    relative_path = os.path.relpath(file, segmented_output_dir)\n",
    "    segment_output_dir = os.path.dirname(os.path.join(output_folder, relative_path))\n",
    "    os.makedirs(segment_output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    spectrogram_output_file = os.path.join(segment_output_dir, f\"{base_name}_spectrogram.png\")\n",
    "        \n",
    "    # Salva lo spettrogramma come immagine\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.axis('off')  # Disabilita gli assi\n",
    "    plt.savefig(spectrogram_output_file, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "def check_memory_and_cleanup():\n",
    "    memory_usage = psutil.virtual_memory().percent\n",
    "    if memory_usage > memory_threshold * 100:\n",
    "        gc.collect()\n",
    "\n",
    "# Generare spettrogrammi per tutti i file audio segmentati e salvarli nella directory di output corrispondente\n",
    "with tqdm(total=len(audio_segmented), desc='Generazione degli spettrogrammi') as pbar:\n",
    "    for file in audio_segmented:\n",
    "        if file not in spectrogram_files:\n",
    "            generate_spectrogram(file, spectrogram_output_dir)\n",
    "            spectrogram_files.add(file)\n",
    "            save_checkpoint(spectrogram_files, spectrogram_checkpoint_file)\n",
    "        check_memory_and_cleanup()\n",
    "        pbar.update(1)\n",
    "#ciao\n",
    "print(\"Processo completato.\")\n"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

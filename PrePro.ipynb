{
 "cells": [
  {
   "cell_type": "code",
   "id": "b7e2e4ec64d2a471",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Importazione delle librerie necessarie\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm  # Importa la libreria tqdm per la progress bar\n",
    "import psutil\n",
    "import gc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Definizione delle directory di input e output\n",
    "input_dir = 'Dataset1/Non-Target/Antarctic Minke Whale'\n",
    "output_dir = 'NuovoDataset'\n",
    "\n",
    "# Creare la directory di output se non esiste\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Definizione della lunghezza desiderata in secondi e in campioni\n",
    "desired_length_sec = 4  # Durata desiderata in secondi\n",
    "sampling_rate = 192000  # Frequenza di campionamento (modifica se necessario)\n",
    "desired_length_samples = int(desired_length_sec * sampling_rate)\n",
    "\n",
    "# Lista per memorizzare i percorsi dei file audio\n",
    "audio_files = []"
   ],
   "id": "ef74998132432f0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scorrere ricorsivamente le cartelle nel dataset\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_files.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio trovati: {len(audio_files)}\")"
   ],
   "id": "ae156121ce29c986",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalize_audio(input_file, output_file):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Trova il valore massimo assoluto nel segnale audio\n",
    "    max_val = np.max(np.abs(audio_data))\n",
    "    \n",
    "    # Normalizza il segnale tra 0 e 1\n",
    "    normalized_audio = (audio_data / max_val + 1) / 2\n",
    "    \n",
    "    # Scrivi il file audio normalizzato\n",
    "    sf.write(output_file, normalized_audio, sample_rate)\n",
    "\n",
    "output_dir = \"NuovoDataset\"\n",
    "for file in tqdm(audio_files, desc='Normalizzazione degli audio'):\n",
    "    relative_path = os.path.relpath(file, input_dir)\n",
    "    output_file = os.path.join(output_dir, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    normalize_audio(file, output_file)"
   ],
   "id": "98b7cebfbaa54567",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio_norm = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset normalizzato\n",
    "for root, dirs, files in os.walk(output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_norm.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio trovati: {len(audio_norm)}\")"
   ],
   "id": "f6a8275666046f05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_audio(input_file, output_directory, segment_duration=4):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Calcola il numero di campioni per ogni segmento\n",
    "    segment_samples = int(segment_duration * sample_rate)\n",
    "    \n",
    "    # Ottieni il nome del file originale senza estensione\n",
    "    original_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    \n",
    "    # Inizializza il contatore per i segmenti\n",
    "    segment_counter = 0\n",
    "    \n",
    "    # Itera attraverso l'audio e salva i segmenti\n",
    "    for start in range(0, len(audio_data), segment_samples):\n",
    "        end = start + segment_samples\n",
    "        segment_data = audio_data[start:end]\n",
    "        \n",
    "        # Costruisci il nome del file per il segmento\n",
    "        segment_filename = f\"{original_filename}_segment_{segment_counter}.wav\"\n",
    "        output_file = os.path.join(output_directory, segment_filename)\n",
    "        \n",
    "        # Crea la directory di output se non esiste\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        \n",
    "        # Scrivi il file audio del segmento\n",
    "        sf.write(output_file, segment_data, sample_rate)\n",
    "        \n",
    "        # Incrementa il contatore dei segmenti\n",
    "        segment_counter += 1\n",
    "\n",
    "output_dir_segment = 'NuovoDataset'\n",
    "for file in tqdm(audio_norm, desc='Suddivisione degli audio'):\n",
    "    relative_path = os.path.relpath(file, output_dir)\n",
    "    output_directory = os.path.join(output_dir_segment, os.path.dirname(relative_path))\n",
    "    split_audio(file, output_directory)\n"
   ],
   "id": "7f2afc71d0bb10ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio_segmented = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset\n",
    "for root, dirs, files in os.walk(output_dir_segment):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_segmented.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio trovati: {len(audio_segmented)}\")\n"
   ],
   "id": "4a120e2dea930cd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "memory_threshold = 0.8  # Soglia di memoria (80%)\n",
    "\n",
    "def generate_spectrogram(file, output_folder):\n",
    "    # Controlla l'estensione del file\n",
    "    if file.endswith('.mp3'):\n",
    "        audio = AudioSegment.from_mp3(file).set_frame_rate(sampling_rate).set_channels(1)\n",
    "        y = np.array(audio.get_array_of_samples(), dtype=np.float32)\n",
    "        sr = audio.frame_rate\n",
    "    else:  # file.endswith('.wav')\n",
    "        y, sr = sf.read(file, always_2d=False)\n",
    "        if len(y.shape) > 1:  # Se stereo, converte in mono\n",
    "            y = librosa.to_mono(y.T)\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=sampling_rate)\n",
    "        sr = sampling_rate\n",
    "    \n",
    "    # Calcola lo spettrogramma STFT\n",
    "    D = np.abs(librosa.stft(y))  # Magnitude of the STFT\n",
    "    D_db = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    \n",
    "    # Creare la struttura delle directory di output mantenendo la stessa gerarchia\n",
    "    relative_path = os.path.relpath(file, input_dir)\n",
    "    segment_output_dir = os.path.splitext(os.path.join(output_folder, relative_path))[0]\n",
    "    os.makedirs(os.path.dirname(segment_output_dir), exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    spectrogram_output_file = f\"{segment_output_dir}_spectrogram.png\"\n",
    "        \n",
    "    # Salva lo spettrogramma come immagine\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.axis('off')  # Disabilita gli assi\n",
    "    plt.savefig(spectrogram_output_file, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "def check_memory_and_cleanup():\n",
    "    memory_usage = psutil.virtual_memory().percent\n",
    "    if memory_usage > memory_threshold * 100:\n",
    "        gc.collect()"
   ],
   "id": "ffc65254d062985a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_folder = 'NuovoDataset'\n",
    "\n",
    "with tqdm(total=len(audio_segmented), desc='Generazione degli spettrogrammi') as pbar:\n",
    "    for file in audio_segmented: \n",
    "        generate_spectrogram(file, output_folder)\n",
    "        check_memory_and_cleanup()\n",
    "        pbar.update(1)"
   ],
   "id": "c9e5f5e8446591f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

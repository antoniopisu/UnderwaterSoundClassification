{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Underwater Sound Analysis\n",
    "## General imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf9b60a6dd29910b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## In questa fase si estraggono le features, così da salvarle in csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c64ce2d3503064d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_audio_features(audio_path):\n",
    "    \n",
    "    percorso_normalizzato = os.path.normpath(audio_path)\n",
    "    elementi = percorso_normalizzato.split(os.sep)\n",
    "    \n",
    "    dataset = elementi[0]\n",
    "    tipo_target = elementi[1]\n",
    "    nome_target = elementi[2]\n",
    "    nome_file_audio = elementi[-1]\n",
    "    \n",
    "    y, sr = librosa.load(audio_path, sr=None, mono=False)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    channels = 'Mono' if y.ndim == 1 else 'Stereo'\n",
    "    \n",
    "    return {'Root': tipo_target, 'Type': nome_target, 'Name': nome_file_audio, 'Durata(s)': duration, 'Canali': channels, 'Frequenza(Hz)': sr}\n",
    "\n",
    "\n",
    "def scrivi_csv(audio_features, csv_file):\n",
    "    if not audio_features:\n",
    "        return  # Se la lista è vuota, non fare nulla\n",
    "\n",
    "    # Ottieni le chiavi dal primo dizionario per usarle come intestazioni\n",
    "    keys = audio_features[0].keys()\n",
    "\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=keys)\n",
    "        \n",
    "        # Scrivi l'intestazione\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Scrivi le caratteristiche\n",
    "        for features in audio_features:\n",
    "            writer.writerow(features)\n",
    "\n",
    "# Lista per memorizzare i percorsi dei file audio\n",
    "audio_files = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset\n",
    "for root, dirs, files in os.walk('NuovoDataset/Segmented/Non-Target'):\n",
    "    for file in files:\n",
    "        if file.endswith(('.wav','.mp3')):\n",
    "           audio_files.append(os.path.join(root, file))\n",
    "audio_features = []\n",
    "\n",
    "for file in audio_files:\n",
    "\n",
    "    feature1 = extract_audio_features(file)\n",
    "    audio_features.append(feature1)\n",
    "    \n",
    "#scrittura nel file csv\n",
    "csv_file = 'Features.csv'\n",
    "scrivi_csv(audio_features, csv_file)\n",
    "\n",
    "# Leggi il file CSV con una codifica diversa\n",
    "df = pd.read_csv('Features.csv', encoding='cp1252')\n",
    "pd.set_option('display.max_rows', None)\n",
    "df['Duplicate'] = df.duplicated(keep=False)\n",
    "# Mostra il dataframe\n",
    "display(df)"
   ],
   "id": "adf876159fd7af5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Somma in secondi degli audio per ciascuna classe\n",
    "### Serve per capire come gestire la fase di data augumentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5f0c3fd73afa960"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "class_duration_sum = df.groupby('Type')['Durata(s)'].sum()\n",
    "\n",
    "filtered_classes = class_duration_sum[class_duration_sum > 10000]\n",
    "# Creazione del grafico a barre\n",
    "plt.figure(figsize=(14, 8))\n",
    "class_duration_sum.plot(kind='bar')\n",
    "plt.title('Somma totale dei secondi per classe')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Somma totale dei secondi')\n",
    "plt.xticks(rotation=90, fontsize=10, horizontalalignment='right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Classi più grandi di 10000s: {filtered_classes}\")\n",
    "media_filtered = np.median(filtered_classes)\n",
    "print(f\"Media degli adio filtrati: {media_filtered}s\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f03234dc82520277",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stampa di tutti gli audio duplicati"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d880d506eebdbd98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "file_names = [os.path.basename(file) for file in audio_files]\n",
    "\n",
    "file_counts = Counter(file_names)\n",
    "duplicates_info = {}\n",
    "# Creare un dizionario per mantenere traccia del percorso del file originale\n",
    "original_paths = {}\n",
    "\n",
    "for file_path in audio_files:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if file_counts[file_name] > 1:\n",
    "        if file_name not in duplicates_info:\n",
    "            duplicates_info[file_name] = {\n",
    "                \"count\": file_counts[file_name],\n",
    "                \"paths\": [file_path]\n",
    "            }\n",
    "            # Memorizza il percorso del file originale\n",
    "            original_paths[file_name] = file_path\n",
    "        else:\n",
    "            duplicates_info[file_name][\"count\"] += 1\n",
    "            duplicates_info[file_name][\"paths\"].append(file_path)\n",
    "\n",
    "# Stampare informazioni sui file duplicati\n",
    "total_duplicate_count = sum(info[\"count\"] for info in duplicates_info.values())\n",
    "print(f\"Numero totale di file audio duplicati: {total_duplicate_count/3}\")\n",
    "\n",
    "for file_name, info in duplicates_info.items():\n",
    "    print(f\"Nome del file duplicato: {file_name}\")\n",
    "    print(f\"Percorsi duplicati ({info['count']-1}):\")\n",
    "    for path in info[\"paths\"]:\n",
    "        print(path)\n",
    "    print(f\"Percorso del file originale: {original_paths[file_name]}\")\n",
    "    print()"
   ],
   "id": "9307e3a64efc3611",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calcoliamo la distribuzione delle classi"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9278c1d1e15dc6c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esempio di grafico a barre delle classi nel dataset\n",
    "plt.figure(figsize=(18, 10))\n",
    "df['Type'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribuzione delle classi')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Numero di campioni')\n",
    "plt.show()"
   ],
   "id": "6463e1b5e77bbf6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distribuzione della durata degli audio\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f83d3c534a1f8106"
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Lista delle durate\n",
    "durations = [feat['Durata(s)'] for feat in audio_features]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(durations, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribuzione della Durata degli Audio', fontsize=16, weight='bold')\n",
    "plt.xlabel('Durata(s)', fontsize=14)\n",
    "plt.ylabel('Numero di Campioni', fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Aggiunta annotazioni\n",
    "median_duration = np.median(durations)\n",
    "plt.axvline(median_duration, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.text(median_duration, plt.ylim()[1] * 0.9, f'Median: {median_duration:.2f}s', color='red', fontsize=12)\n",
    "\n",
    "# Aggiungi griglia\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Visualizza il grafico\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd7397add093579d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distribuzione delle frequenze audio\n",
    "### Si usa per capire a quale frequenza ricampionare"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efea10e79f08744b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Imposta il tema di Seaborn per migliorare l'estetica\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Frequenze di campionamento (assumendo che audio_features sia definito)\n",
    "frequencies = [feat['Frequenza(Hz)'] for feat in audio_features]\n",
    "\n",
    "# Creazione del grafico della distribuzione della frequenza di campionamento\n",
    "plt.figure(figsize=(12, 8))  # Dimensioni maggiori per una migliore leggibilità\n",
    "plt.hist(frequencies, bins=20, color='salmon', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribuzione della Frequenza di Campionamento', fontsize=16, weight='bold')\n",
    "plt.xlabel('Frequenza(Hz)', fontsize=14)\n",
    "plt.ylabel('Numero di Campioni', fontsize=14)\n",
    "\n",
    "# Migliora le etichette degli assi\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Aggiungi annotazioni per la frequenza massima e la mediana\n",
    "freq_max = max(frequencies)\n",
    "median_freq = np.median(frequencies)\n",
    "plt.axvline(freq_max, color='blue', linestyle='dashed', linewidth=1.5)\n",
    "plt.axvline(median_freq, color='green', linestyle='dashed', linewidth=1.5)\n",
    "plt.text(freq_max, plt.ylim()[1] * 0.9, f'Max: {freq_max} Hz', color='blue', fontsize=12, ha='right')\n",
    "plt.text(median_freq, plt.ylim()[1] * 0.7, f'Median: {median_freq} Hz', color='green', fontsize=12, ha='right')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "hist, bins = np.histogram(frequencies, bins=20)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e15524ddf83ecddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### La mediana è il valore centrale che separa la metà superiore dei dati dalla metà inferiore. Essa non è influenzata dai valori anomali, come la media, e fornisce una misura più rappresentativa della frequenza di campionamento tipica."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f07387d93f774be"
  },
  {
   "cell_type": "code",
   "source": [
    "tabella_dati = []\n",
    "for i in range(len(hist)):\n",
    "    tabella_dati.append((f\"{bins[i]:.2f} - {bins[i+1]:.2f} Hz\", hist[i]))\n",
    "# Stampa della tabella\n",
    "print(tabulate(tabella_dati, headers=[\"Intervallo di frequenza\", \"Numero di campioni\"], tablefmt=\"pretty\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfe923a23add7d7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### qui spieghiamo perché scegliamo di campionare a determinati Hz"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55dc5099611cf7ae"
  },
  {
   "cell_type": "code",
   "source": [
    "statistiche_frequenze = [\n",
    "    (\"Frequenza massima\", freq_max),\n",
    "    (\"Mediana delle frequenze\", median_freq)\n",
    "]\n",
    "\n",
    "print(tabulate(statistiche_frequenze, headers=[\"Statistiche\", \"Valore (Hz)\"], tablefmt=\"pretty\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e5ae89e4b37d79b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Serve per vedere i percorsi degli audio che andremo a tagliare"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d47553220f3ef4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def estrai_path_e_conta_frequenze(audio_features, frequenza_minima):\n",
    "    # Filtra i file audio per la frequenza di campionamento minima specificata\n",
    "    # paths = [feat['Audio'] for feat in audio_features if feat['Frequenza(Hz)'] >= frequenza_minima]\n",
    "    paths = [\n",
    "        f\"Dataset/{feat['Root']}/{feat['Type']}/{feat['Name']}\" \n",
    "        for feat in audio_features \n",
    "        if feat['Frequenza(Hz)'] >= frequenza_minima\n",
    "    ]\n",
    "    total_frequencies = len(paths)\n",
    "    return paths, total_frequencies\n",
    "\n",
    "# Frequenza minima desiderata (Hz)\n",
    "frequenza_minima = 200001\n",
    "\n",
    "# Estrazione dei path e conteggio delle frequenze per la frequenza minima specificata\n",
    "paths, total_frequencies = estrai_path_e_conta_frequenze(audio_features, frequenza_minima)\n",
    "\n",
    "# Stampa dei percorsi estratti\n",
    "print(f\"Percorsi dei file audio con frequenza di campionamento ≥ {frequenza_minima} Hz:\")\n",
    "for path in paths:\n",
    "    print(path)\n",
    "\n",
    "# Stampa del numero totale di frequenze trovate\n",
    "print(f\"\\nNumero totale di frequenze trovate: {total_frequencies}\")"
   ],
   "id": "bc805587ea0bcc37",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "qui evidenziamo quali audio superano una determinata soglia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "233e3c28b5cb9906"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mono/Stereo counting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44c2a2499e5c0926"
  },
  {
   "cell_type": "code",
   "source": [
    "channels = [feat['Canali'] for feat in audio_features]\n",
    "\n",
    "# Grafico del conteggio di mono/stereo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Mono', 'Stereo'], [channels.count('Mono'), channels.count('Stereo')], color=['lightgreen', 'lightcoral'], edgecolor=['black','black'])\n",
    "plt.title('Conteggio di Mono/Stereo')\n",
    "plt.xlabel('Tipo di Canale')\n",
    "plt.ylabel('Conteggio')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b64e6eae8d501728",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Depth Bit Counts\n",
    "\n",
    "### Durante l'analisi del dataset abbiamo trovato file di tipo mp3 e wav. Il bit depth è un concetto applicabile solamente ai file wav mentre i file mp3 vengono compressi e di conseguenza hanno il bitrate. Il bitrate è l'unità di misura che quantifica la quantità di audio compressi al secondo, non utili alle analisi di nostro interesse."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85ad49e79dbf450a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for root, dirs, files in os.walk('Dataset'):\n",
    "    for file in files:\n",
    "        if file.endswith(('.wav')):\n",
    "           audio_files.append(os.path.join(root, file))\n",
    "# Creare un dizionario per tenere traccia del conteggio di ciascun valore\n",
    "depth_bit_counts = {}\n",
    "\n",
    "for file in audio_files:\n",
    "    audio = sf.SoundFile(file)\n",
    "    depth_bit = audio.subtype\n",
    "    \n",
    "    # Aggiungere il valore al dizionario o incrementare il conteggio se già presente\n",
    "    if depth_bit in depth_bit_counts:\n",
    "        depth_bit_counts[depth_bit] += 1\n",
    "    else:\n",
    "        depth_bit_counts[depth_bit] = 1\n",
    "\n",
    "# Estrai i dati per il grafico\n",
    "depth_bits = list(depth_bit_counts.keys())\n",
    "counts = list(depth_bit_counts.values())\n",
    "\n",
    "# Creare il grafico a barre con dimensioni specificate\n",
    "plt.figure(figsize=(10, 6))  # Imposta la dimensione della figura a 12x8 pollici\n",
    "plt.bar(depth_bits, counts, color='lightgreen', edgecolor='black')\n",
    "plt.xlabel('Depth Bit', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Depth Bit Counts', fontsize=16, weight='bold')\n",
    "\n",
    "# Migliora le etichette degli assi\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Aggiungi una griglia per migliorare la leggibilità\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ],
   "id": "e4b9ab7e4458f221",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Durante l'analisi del dataset abbiamo trovato file di tipo mp3 e wav. Il bit depth è un concetto applicabile solamente ai file wav mentre i file mp3 vengono compressi e di conseguenza hanno il bitrate. Il bitrate è l'unità di misura che quantifica la quantità di audio compressi al secondo, non utili alle analisi di nostro interesse.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4032587f5943e2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

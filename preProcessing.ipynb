{
 "cells": [
  {
   "cell_type": "code",
   "id": "b7e2e4ec64d2a471",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T18:17:13.547276Z",
     "start_time": "2024-06-19T18:17:13.536164Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import gc\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:17:20.273487Z",
     "start_time": "2024-06-19T18:17:20.257404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Definizione delle directory di input e output\n",
    "input_dir = 'DatasetTVT'\n",
    "normalized_output_dir = 'NuovoDataset/Normalized'\n",
    "segmented_output_dir = 'NuovoDataset/Segmented/Training/Target/Tug'\n",
    "spectrogram_output_dir = 'NuovoDataset/Spectrograms/Training/Target/Tug'\n",
    "\n",
    "# Creare le directory di output se non esistono\n",
    "os.makedirs(normalized_output_dir, exist_ok=True)\n",
    "os.makedirs(segmented_output_dir, exist_ok=True)\n",
    "os.makedirs(spectrogram_output_dir, exist_ok=True)\n",
    "\n",
    "# Definizione della lunghezza desiderata in secondi e in campioni\n",
    "desired_length_sec = 4  # Durata desiderata in secondi\n",
    "sampling_rate = 192000  # Frequenza di campionamento (modifica se necessario)\n",
    "\n"
   ],
   "id": "ef74998132432f0f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:17:23.100825Z",
     "start_time": "2024-06-19T18:17:23.053340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lista per memorizzare i percorsi dei file audio\n",
    "audio_files = []\n",
    "# Scorrere ricorsivamente le cartelle nel dataset\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_files.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio trovati: {len(audio_files)}\")"
   ],
   "id": "ae156121ce29c986",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file audio trovati: 2458\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T16:18:12.606827Z",
     "start_time": "2024-06-19T16:18:00.035866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def normalize_audio(input_file, output_file):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Trova il valore massimo assoluto nel segnale audio\n",
    "    max_val = np.max(np.abs(audio_data))\n",
    "    \n",
    "    # Normalizza il segnale tra 0 e 1\n",
    "    normalized_audio = (audio_data / max_val + 1) / 2\n",
    "    \n",
    "    # Scrivi il file audio normalizzato\n",
    "    sf.write(output_file, normalized_audio, sample_rate)\n",
    "\n",
    "# Normalizzare tutti i file audio e salvarli nella directory di output corrispondente\n",
    "for file in tqdm(audio_files, desc='Normalizzazione degli audio'):\n",
    "    relative_path = os.path.relpath(file, input_dir)\n",
    "    output_file = os.path.join(normalized_output_dir, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    normalize_audio(file, output_file)\n",
    "\n",
    "\n"
   ],
   "id": "98b7cebfbaa54567",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizzazione degli audio:   3%|â–Ž         | 81/2458 [00:12<05:57,  6.66it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m output_file \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(normalized_output_dir, relative_path)\n\u001B[0;32m     18\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(output_file), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 19\u001B[0m \u001B[43mnormalize_audio\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 12\u001B[0m, in \u001B[0;36mnormalize_audio\u001B[1;34m(input_file, output_file)\u001B[0m\n\u001B[0;32m      9\u001B[0m normalized_audio \u001B[38;5;241m=\u001B[39m (audio_data \u001B[38;5;241m/\u001B[39m max_val \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Scrivi il file audio normalizzato\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m \u001B[43msf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalized_audio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_rate\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\University\\FVAB - Nappi\\Project\\venv\\lib\\site-packages\\soundfile.py:345\u001B[0m, in \u001B[0;36mwrite\u001B[1;34m(file, data, samplerate, subtype, endian, format, closefd)\u001B[0m\n\u001B[0;32m    342\u001B[0m     channels \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SoundFile(file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m, samplerate, channels,\n\u001B[0;32m    344\u001B[0m                subtype, endian, \u001B[38;5;28mformat\u001B[39m, closefd) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 345\u001B[0m     \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\University\\FVAB - Nappi\\Project\\venv\\lib\\site-packages\\soundfile.py:1020\u001B[0m, in \u001B[0;36mSoundFile.write\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1018\u001B[0m \u001B[38;5;66;03m# no copy is made if data has already the correct memory layout:\u001B[39;00m\n\u001B[0;32m   1019\u001B[0m data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mascontiguousarray(data)\n\u001B[1;32m-> 1020\u001B[0m written \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_array_io\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwrite\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1021\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m written \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(data)\n\u001B[0;32m   1022\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_frames(written)\n",
      "File \u001B[1;32m~\\Documents\\University\\FVAB - Nappi\\Project\\venv\\lib\\site-packages\\soundfile.py:1344\u001B[0m, in \u001B[0;36mSoundFile._array_io\u001B[1;34m(self, action, array, frames)\u001B[0m\n\u001B[0;32m   1342\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mitemsize \u001B[38;5;241m==\u001B[39m _ffi\u001B[38;5;241m.\u001B[39msizeof(ctype)\n\u001B[0;32m   1343\u001B[0m cdata \u001B[38;5;241m=\u001B[39m _ffi\u001B[38;5;241m.\u001B[39mcast(ctype \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m, array\u001B[38;5;241m.\u001B[39m__array_interface__[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m-> 1344\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cdata_io\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\University\\FVAB - Nappi\\Project\\venv\\lib\\site-packages\\soundfile.py:1353\u001B[0m, in \u001B[0;36mSoundFile._cdata_io\u001B[1;34m(self, action, data, ctype, frames)\u001B[0m\n\u001B[0;32m   1351\u001B[0m     curr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m   1352\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(_snd, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msf_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m action \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m ctype)\n\u001B[1;32m-> 1353\u001B[0m frames \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1354\u001B[0m _error_check(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_errorcode)\n\u001B[0;32m   1355\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseekable():\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:50:06.500277Z",
     "start_time": "2024-06-18T11:50:06.441272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_norm = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset normalizzato\n",
    "for root, dirs, files in os.walk(normalized_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_norm.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio normalizzati: {len(audio_norm)}\")"
   ],
   "id": "f6a8275666046f05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file audio normalizzati: 2458\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:54:07.207779Z",
     "start_time": "2024-06-18T11:50:13.329473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def split_audio(input_file, output_directory, segment_duration=4):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Calcola il numero di campioni per ogni segmento\n",
    "    segment_samples = int(segment_duration * sample_rate)\n",
    "    \n",
    "    # Ottieni il nome del file originale senza estensione\n",
    "    original_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    \n",
    "    # Inizializza il contatore per i segmenti\n",
    "    segment_counter = 0\n",
    "    \n",
    "    # Itera attraverso l'audio e salva i segmenti\n",
    "    for start in range(0, len(audio_data), segment_samples):\n",
    "        end = start + segment_samples\n",
    "        segment_data = audio_data[start:end]\n",
    "        \n",
    "        # Costruisci il nome del file per il segmento\n",
    "        segment_filename = f\"{original_filename}_segment_{segment_counter}.wav\"\n",
    "        output_file = os.path.join(output_directory, segment_filename)\n",
    "        \n",
    "        # Crea la directory di output se non esiste\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        \n",
    "        # Scrivi il file audio del segmento\n",
    "        sf.write(output_file, segment_data, sample_rate)\n",
    "        \n",
    "        # Incrementa il contatore dei segmenti\n",
    "        segment_counter += 1\n",
    "\n",
    "# Dividere tutti i file audio normalizzati in segmenti e salvarli nella directory di output corrispondente\n",
    "for file in tqdm(audio_norm, desc='Suddivisione degli audio'):\n",
    "    relative_path = os.path.relpath(file, normalized_output_dir)\n",
    "    output_directory = os.path.join(segmented_output_dir, os.path.dirname(relative_path))\n",
    "    split_audio(file, output_directory)\n"
   ],
   "id": "7f2afc71d0bb10ee",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Suddivisione degli audio: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2458/2458 [03:53<00:00, 10.51it/s] \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:17:28.042047Z",
     "start_time": "2024-06-19T18:17:27.981062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "audio_segmented = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset segmentato\n",
    "for root, dirs, files in os.walk(segmented_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_segmented.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio segmentati: {len(audio_segmented)}\")\n"
   ],
   "id": "4a120e2dea930cd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file audio segmentati: 7897\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STOP O ESPLODE!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcd14b06fe370d3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T18:22:12.598919Z",
     "start_time": "2024-06-19T18:17:30.202406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "memory_threshold = 0.8  # Soglia di memoria (80%)\n",
    "\n",
    "def generate_spectrogram(file, output_folder):\n",
    "    # Controlla l'estensione del file\n",
    "    if file.endswith('.mp3'):\n",
    "        audio = AudioSegment.from_mp3(file).set_frame_rate(sampling_rate).set_channels(1)\n",
    "        y = np.array(audio.get_array_of_samples(), dtype=np.float32)\n",
    "        sr = audio.frame_rate\n",
    "    else:  # file.endswith('.wav')\n",
    "        y, sr = sf.read(file, always_2d=False)\n",
    "        if len(y.shape) > 1:  # Se stereo, converte in mono\n",
    "            y = librosa.to_mono(y.T)\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=sampling_rate)\n",
    "        sr = sampling_rate\n",
    "    \n",
    "    # Calcola lo spettrogramma STFT\n",
    "    D = np.abs(librosa.stft(y))  # Magnitude of the STFT\n",
    "    D_db = librosa.amplitude_to_db(D, ref=np.max)\n",
    "    \n",
    "    # Creare la struttura delle directory di output mantenendo la stessa gerarchia\n",
    "    relative_path = os.path.relpath(file, segmented_output_dir)\n",
    "    segment_output_dir = os.path.dirname(os.path.join(output_folder, relative_path))\n",
    "    os.makedirs(segment_output_dir, exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    spectrogram_output_file = os.path.join(segment_output_dir, f\"{base_name}_spectrogram.png\")\n",
    "        \n",
    "    # Salva lo spettrogramma come immagine\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.axis('off')  # Disabilita gli assi\n",
    "    plt.savefig(spectrogram_output_file, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "def check_memory_and_cleanup():\n",
    "    memory_usage = psutil.virtual_memory().percent\n",
    "    if memory_usage > memory_threshold * 100:\n",
    "        gc.collect()\n",
    "\n",
    "def process_audio_files(audio_files, output_folder):\n",
    "    # Carica il file di log dei file processati\n",
    "    checkpoint_file = 'processed_files.log'\n",
    "    processed_files = set()\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            processed_files = set(f.read().splitlines())\n",
    "    \n",
    "    with tqdm(total=len(audio_files), desc='Generazione degli spettrogrammi') as pbar:\n",
    "        for file in audio_files: \n",
    "            if file in processed_files:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            generate_spectrogram(file, output_folder)\n",
    "            check_memory_and_cleanup()\n",
    "            processed_files.add(file)\n",
    "            # Aggiorna il file di log\n",
    "            with open(checkpoint_file, 'a') as f:\n",
    "                f.write(file + '\\n')\n",
    "            pbar.update(1)\n",
    "\n",
    "# Generare spettrogrammi per tutti i file audio segmentati e salvarli nella directory di output corrispondente\n",
    "process_audio_files(audio_segmented, spectrogram_output_dir)"
   ],
   "id": "ffc65254d062985a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generazione degli spettrogrammi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7897/7897 [04:42<00:00, 27.97it/s]  \n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

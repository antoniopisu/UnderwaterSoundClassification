{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PreProcessing "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bfcbd46daa67972"
  },
  {
   "cell_type": "code",
   "id": "b7e2e4ec64d2a471",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-07T19:55:49.211682Z",
     "start_time": "2024-07-07T19:55:49.043324Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import gc\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\anaconda3\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## In questa fase andiamo a scegliere il numero di secondi per segmentare gli audio, e il sampling_rate per effettuare il campionamento"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd1f033d552f5afe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T15:35:42.131016Z",
     "start_time": "2024-06-18T15:35:42.122524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Definizione delle directory di input e output\n",
    "input_dir = 'DatasetTVT'\n",
    "normalized_output_dir = 'Prova/Normalized'\n",
    "segmented_output_dir = 'Prova/Segmented'\n",
    "spectrogram_output_dir = 'Prova/Spectrogram'\n",
    "\n",
    "# Creare le directory di output se non esistono\n",
    "os.makedirs(normalized_output_dir, exist_ok=True)\n",
    "os.makedirs(segmented_output_dir, exist_ok=True)\n",
    "os.makedirs(spectrogram_output_dir, exist_ok=True)\n",
    "\n",
    "# Definizione della lunghezza desiderata in secondi e in campioni\n",
    "desired_length_sec = 4  # Durata desiderata in secondi\n",
    "sampling_rate = 192000  # Frequenza di campionamento (modifica se necessario)\n",
    "\n"
   ],
   "id": "ef74998132432f0f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T15:58:45.206539Z",
     "start_time": "2024-06-17T15:58:45.039544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lista per memorizzare i percorsi dei file audio\n",
    "audio_files = []\n",
    "# Scorrere ricorsivamente le cartelle nel dataset\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_files.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio trovati: {len(audio_files)}\")"
   ],
   "id": "ae156121ce29c986",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file audio trovati: 2458\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalizzazione\n",
    "## Tutti gli audio sono stati normalizzati in modo tale da avere il segnale tra 0 e 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "966ade1d4b43e153"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:02:16.717859Z",
     "start_time": "2024-06-17T15:58:46.365198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def normalize_audio(input_file, output_file):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Trova il valore massimo assoluto nel segnale audio\n",
    "    max_val = np.max(np.abs(audio_data))\n",
    "    \n",
    "    # Normalizza il segnale tra 0 e 1\n",
    "    normalized_audio = (audio_data / max_val + 1) / 2\n",
    "    \n",
    "    # Scrivi il file audio normalizzato\n",
    "    sf.write(output_file, normalized_audio, sample_rate)\n",
    "\n",
    "# Normalizzare tutti i file audio e salvarli nella directory di output corrispondente\n",
    "for file in tqdm(audio_files, desc='Normalizzazione degli audio'):\n",
    "    relative_path = os.path.relpath(file, input_dir)\n",
    "    output_file = os.path.join(normalized_output_dir, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    normalize_audio(file, output_file)"
   ],
   "id": "98b7cebfbaa54567",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizzazione degli audio: 100%|██████████| 2458/2458 [03:30<00:00, 11.69it/s] \n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:02:16.818805Z",
     "start_time": "2024-06-17T16:02:16.722417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_norm = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset normalizzato\n",
    "for root, dirs, files in os.walk(normalized_output_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_norm.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio normalizzati: {len(audio_norm)}\")"
   ],
   "id": "f6a8275666046f05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file audio normalizzati: 2458\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split audio\n",
    "## In questa fase andiamo a segmentare gli audio a 4 secondi"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adf3d2e9e7c6e9fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T16:08:49.717796Z",
     "start_time": "2024-06-17T16:02:16.822154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def split_audio(input_file, output_directory, segment_duration=4):\n",
    "    # Carica il file audio\n",
    "    audio_data, sample_rate = librosa.load(input_file, sr=None)\n",
    "    \n",
    "    # Calcola il numero di campioni per ogni segmento\n",
    "    segment_samples = int(segment_duration * sample_rate)\n",
    "    \n",
    "    # Ottieni il nome del file originale senza estensione\n",
    "    original_filename = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    \n",
    "    # Inizializza il contatore per i segmenti\n",
    "    segment_counter = 0\n",
    "    \n",
    "    # Calcola il numero totale di segmenti necessari\n",
    "    total_segments = int(np.ceil(len(audio_data) / segment_samples))\n",
    "    \n",
    "    # Itera attraverso l'audio e salva i segmenti\n",
    "    for segment_index in range(total_segments):\n",
    "        start = segment_index * segment_samples\n",
    "        end = min(start + segment_samples, len(audio_data))  # Evita di superare la lunghezza dell'audio\n",
    "        \n",
    "        # Estrai il segmento dell'audio\n",
    "        segment_data = audio_data[start:end]\n",
    "        \n",
    "        # Se il segmento è più corto del segmento desiderato, aggiungi silenzio\n",
    "        if len(segment_data) < segment_samples:\n",
    "            padding = np.zeros(segment_samples - len(segment_data))\n",
    "            segment_data = np.concatenate((segment_data, padding))\n",
    "        \n",
    "        # Costruisci il nome del file per il segmento\n",
    "        segment_filename = f\"{original_filename}_segment_{segment_counter}.wav\"\n",
    "        output_file = os.path.join(output_directory, segment_filename)\n",
    "        \n",
    "        # Crea la directory di output se non esiste\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        \n",
    "        # Scrivi il file audio del segmento\n",
    "        sf.write(output_file, segment_data, sample_rate)\n",
    "        \n",
    "        # Incrementa il contatore dei segmenti\n",
    "        segment_counter += 1\n",
    "\n",
    "# Dividere tutti i file audio normalizzati in segmenti e salvarli nella directory di output corrispondente\n",
    "for file in tqdm(audio_norm, desc='Suddivisione degli audio'):\n",
    "    relative_path = os.path.relpath(file, normalized_output_dir)\n",
    "    output_directory = os.path.join(segmented_output_dir, os.path.dirname(relative_path))\n",
    "    split_audio(file, output_directory)\n"
   ],
   "id": "7f2afc71d0bb10ee",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Suddivisione degli audio: 100%|██████████| 2458/2458 [06:32<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T15:35:55.150603Z",
     "start_time": "2024-06-18T15:35:55.141402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "audio_segmented = []\n",
    "\n",
    "# Scorrere ricorsivamente le cartelle nel dataset segmentato\n",
    "for root, dirs, files in os.walk(segmented_output_dir):\n",
    "    for file in files:\n",
    "        #if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio_segmented.append(os.path.join(root, file))\n",
    "\n",
    "# Visualizzare il numero di file audio trovati\n",
    "print(f\"Numero di file audio segmentati: {len(audio_segmented)}\")\n"
   ],
   "id": "4a120e2dea930cd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di file audio segmentati: 259\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spettrogrammi\n",
    "## Si prendono in input gli audio segmentati e si generano gli spettrogrammi tramite la trasformata di fourier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcd14b06fe370d3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T15:43:01.180868Z",
     "start_time": "2024-06-18T15:35:57.445365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "memory_threshold = 0.8  # Soglia di memoria (80%)\n",
    "sampling_rate = 192000  # Frequenza di campionamento \n",
    "\n",
    "def generate_spectrogram(file, output_folder):\n",
    "    try:\n",
    "        # Carica il file audio usando librosa\n",
    "        y, sr = librosa.load(file, sr=sampling_rate, mono=True)\n",
    "\n",
    "        # Calcola lo spettrogramma STFT\n",
    "        D = np.abs(librosa.stft(y))  # Magnitude of the STFT\n",
    "        D_db = librosa.amplitude_to_db(D, ref=np.max)\n",
    "        \n",
    "        # Creare la struttura delle directory di output mantenendo la stessa gerarchia\n",
    "        relative_path = os.path.relpath(file, segmented_output_dir)\n",
    "        segment_output_dir = os.path.dirname(os.path.join(output_folder, relative_path))\n",
    "        os.makedirs(segment_output_dir, exist_ok=True)\n",
    "        base_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        spectrogram_output_file = os.path.join(segment_output_dir, f\"{base_name}_spectrogram.png\")\n",
    "            \n",
    "        # Salva lo spettrogramma come immagine\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='log', ax=ax)\n",
    "        ax.axis('off')\n",
    "        plt.savefig(spectrogram_output_file, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Elimina variabili temporanee\n",
    "        del y, D, D_db, fig, ax\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nel processare il file {file}: {e}\")\n",
    "\n",
    "def check_memory_and_cleanup():\n",
    "    memory_usage = psutil.virtual_memory().percent\n",
    "    if memory_usage > memory_threshold * 100:\n",
    "        gc.collect()\n",
    "\n",
    "def process_audio_files(audio_files, output_folder):\n",
    "    # Carica il file di log dei file processati\n",
    "    checkpoint_file = 'processed_files.log'\n",
    "    processed_files = set()\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            processed_files = set(f.read().splitlines())\n",
    "    \n",
    "    with tqdm(total=len(audio_files), desc='Generazione degli spettrogrammi') as pbar:\n",
    "        for file in audio_files:\n",
    "            if file in processed_files:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            generate_spectrogram(file, output_folder)\n",
    "            check_memory_and_cleanup()\n",
    "            processed_files.add(file)\n",
    "            # Aggiorna il file di log\n",
    "            with open(checkpoint_file, 'a') as f:\n",
    "                f.write(file + '\\n')\n",
    "            pbar.update(1)\n",
    "\n",
    "# Generare spettrogrammi per tutti i file audio segmentati e salvarli nella directory di output corrispondente\n",
    "process_audio_files(audio_segmented, spectrogram_output_dir)\n"
   ],
   "id": "ffc65254d062985a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generazione degli spettrogrammi: 100%|██████████| 259/259 [07:03<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
